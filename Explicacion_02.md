# Explicaci√≥n Paso a Paso de `02_limpieza_texto.py`

Este documento explica el segundo ejercicio, donde el objetivo principal es aprender a **eliminar el ruido** (stopwords) del texto para que las palabras con significado real salgan a la luz.

## 1. Librer√≠as Utilizadas

*   **`re` (Expresiones Regulares)**: Se usa para la **Tokenizaci√≥n**. Permite extraer solo las palabras, eliminando signos de puntuaci√≥n de forma inteligente.
*   **`collections.Counter`**: Se encarga del **conteo matem√°tico**. Cuenta autom√°ticamente cu√°ntas veces aparece cada palabra una vez que el texto est√° limpio.
*   **`matplotlib.pyplot`**: Se utiliza para la **visualizaci√≥n comparativa**. En este ejercicio, creamos dos figuras independientes para un an√°lisis profundo.
*   **`wordcloud`**: Genera la **Nube de Palabras**, una forma visual y art√≠stica de identificar temas dominantes.
*   **`rich`**: La librer√≠a estrella de este ejercicio. Se encarga de convertir la aburrida terminal de texto plano en una **interfaz profesional** con colores, tablas, reglas y paneles.

---

## 2. El Concepto de Stopwords (L√≠neas 29-40)

En este paso introducimos la *gran diferencia* respecto al primer ejercicio: **La Limpieza Selectiva**.

Las **Stopwords** son palabras vac√≠as como "el", "la", "de", "que". Aparecen mucho pero no aportan significado.

### üí° Lo Nuevo: Definici√≥n del Filtro
A diferencia del script anterior donde cont√°bamos *todo*, aqu√≠ hemos a√±adido manualmente una lista de palabras a ignorar.

```python
# [NUEVO] Definimos un conjunto (set) con las palabras que queremos ELIMINAR
stopwords_es = set([
    'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'las', 'un', 'por', 
    'con', 'no', 'una', 'su', 'para', 'es', 'al', 'lo', 'como', 'm√°s', 'pero', 
    'sus', 'le', 'ha', 'me', 'sin', 'sobre', 'este', 'ya', 'entre', 'cuando', 
    'todo', 'esta', 'ser', 'son', 'dos', 'tambi√©n', 'fue', 'hab√≠a', 'era', 'muy', 
    'hasta', 'desde', 'mucho', 'hacia', 'mi', 'se', 'ni', 'ese', 'yo', 'qu√©', 
    'e', 'o', 'u', 'algunos', 'aspectos'
])
```

**Explicaci√≥n para tu equipo:**
1.  **¬øPor qu√© un `set` y no una lista?**: En Python, buscar en un `set` (conjunto) es instant√°neo, mientras que buscar en una `list` se vuelve m√°s lento cuantas m√°s palabras tengas. Es una optimizaci√≥n de velocidad.
2.  **Personalizaci√≥n**: Esta lista es totalmente editable. Si analizas textos m√©dicos, podr√≠as a√±adir palabras como "paciente" o "doctor" si consideras que son ruido para tu objetivo espec√≠fico.

---

## 3. Procesamiento Inteligente (Funci√≥n `procesar_y_contar`)

En lugar de repetir c√≥digo, este script usa una **funci√≥n** (l√≠nea 37) que hace tres cosas:
1.  **Normalizaci√≥n**: Pasa todo a min√∫sculas (`.lower()`).
2.  **Tokenizaci√≥n**: Divide el texto en palabras.
3.  **Filtrado (Limpieza)**: Si le pasamos la lista de stopwords, usa una "lista por comprensi√≥n" para quedarse solo con las palabras que NO est√°n en esa lista.
4.  üî¥ <span style="color:red">**NUEVA MEJORA: Filtrado por Longitud**</span>: Ahora el script ignora palabras muy cortas (ej: menos de 3 letras). Esto es clave porque palabras como "ni", "a", "u" o "lo" suelen ser ruido estad√≠stico que no aporta significado.
    ```python
    # Solo guardamos palabras que tengan al menos 'min_len' caracteres
    if min_len > 1:
        words = [word for word in words if len(word) >= min_len]
    ```
5.  **Retorno Doble**: La funci√≥n ahora devuelve tanto la lista de palabras filtradas como el objeto `Counter`.

---

## 4. An√°lisis Comparativo (L√≠neas 45-56)

El script realiza dos an√°lisis sobre el mismo texto:
*   **Paso 1**: Cuenta todas las palabras originales para tener una base de comparaci√≥n.
*   **Paso 2**: Realiza el conteo tras aplicar los dos filtros (Stopwords + Longitud >= 3).
*   üî¥ <span style="color:red">**NUEVA MEJORA: M√©tricas de Eficiencia (Porcentaje de Ruido)**</span>: El script calcula matem√°ticamente cu√°nto texto se elimin√≥.

    ```python
    # Calculamos cu√°ntas palabras hemos eliminado
    total_sin = len(words_sin)
    total_con = len(words_con)
    ruido_eliminado = total_sin - total_con
    
    # Regla de tres simple para sacar el porcentaje
    porcentaje_ruido = (ruido_eliminado / total_sin) * 100
    ```

    *   **M√©trica 1**: Porcentaje de ruido (ej: "46.9% del texto eliminado").
    *   **M√©trica 2**: Cantidad exacta de palabras descartadas.
    Esto permite cuantificar la "limpieza" de nuestros datos.

---

## 5. Visualizaci√≥n de "Impacto" (L√≠neas 63-88)

Para que el aprendizaje sea visual, el script genera una ventana con **dos sub-gr√°ficos** (`subplots`):
*   **Gr√°fico Rojo**: Muestra las palabras dominantes antes de limpiar (ver√°s muchas preposiciones y art√≠culos).
*   **Gr√°fico Verde**: Muestra las palabras que quedan tras la limpieza. 

Aqu√≠ es donde ocurre la "magia": palabras como **'fant√°stico'**, **'producto'** o **'terrible'** pasan a los primeros puestos, permiti√©ndonos entender de qu√© trata realmente el texto.

---

## 7. Estructura de Ventanas (Dos Figuras)

Para que no pierdas ning√∫n detalle, el script ahora genera **dos ventanas independientes** al mismo tiempo con objetivos distintos:

1.  **Figura 1 (Dashboard Avanzado)**: Es una herramienta de **anal√≠tica 360¬∞**.
    *   **Prop√≥sito**: No solo cuenta palabras, sino que busca **interpretar** el mensaje profundo del texto. 
    *   **Nube de Palabras**: Proporciona una jerarqu√≠a visual inmediata; lo m√°s grande es lo m√°s relevante. Es ideal para identificar temas principales en segundos.
    *   **Perfil Emocional**: Clasifica autom√°ticamente el texto en tres categor√≠as cr√≠ticas:
        *   **Positivo**: Identifica satisfacci√≥n, aprobaci√≥n o alegr√≠a (ej: "fant√°stico", "recomiendo"). Ayuda a medir el √©xito de un producto o campa√±a.
        *   **Negativo**: Detecta frustraci√≥n, quejas o problemas (ej: "terrible", "desastre"). Es fundamental para la gesti√≥n de crisis y atenci√≥n al cliente.
        *   **Neutro**: Palabras que informan sin carga emocional (ej: "env√≠o", "precio"). Permite aislar los datos objetivos de las opiniones.
        *   **¬øEn qu√© ayuda?**: Permite procesar miles de opiniones humanas en segundos, identificando tendencias sin tener que leer cada frase manualmente.
    *   **Resumen T√©cnico**: Cuantifica la "limpieza" de los datos, mostrando la eficiencia del proceso (palabras eliminadas, longitud m√≠nima aplicada y t√©rminos √∫nicos).

2.  **Figura 2 (Microscopio de Limpieza)**: Es una herramienta de **validaci√≥n t√©cnica** y pedag√≥gica.
    *   **Prop√≥sito**: Demostrar visualmente por qu√© el NLP requiere un pre-procesamiento riguroso.
    *   **Lado Rojo (Antes)**: Muestra c√≥mo el "ruido" (art√≠culos como 'el', preposiciones como 'de') oculta el mensaje real del autor.
    *   **Lado Verde (Despu√©s)**: Revela las palabras con carga sem√°ntica real (adjetivos, sustantivos, verbos) tras el filtrado.
    *   **Precisi√≥n**: Las etiquetas num√©ricas sobre las barras eliminan cualquier ambig√ºedad, permitiendo ver el conteo exacto de cada t√©rmino.

## 8. Interfaz de Terminal Enriquecida con `Rich`

Para que el proyecto tenga una est√©tica profesional fuera de los gr√°ficos, hemos integrado la librer√≠a `rich`. Esto transforma la experiencia en la consola:

### üî¥ <span style="color:red">**NUEVA MEJORA: Dise√±o de Consola**</span>

*   **Reglas de Secci√≥n (`console.rule`)**: L√≠neas divisorias de colores que separan claramente los pasos del an√°lisis.
    ```python
    console.rule("[bold blue]PASO 1: An√°lisis Inicial (Sin Limpiar)")
    ```

*   **Paneles Informativos (`Panel`)**: Los resultados de las m√©tricas aparecen dentro de recuadros elegantes.
    ```python
    console.print(Panel(metricas_text, title="[bold green]M√©tricas de Eficiencia[/]", expand=False))
    ```

*   **Tablas de Datos (`Table`)**: El "Top 10" ahora es una tabla real con encabezados magenta y columnas alineadas.
    ```python
    tabla = Table(title="[bold yellow]Top 10 Palabras con Significado[/]", show_header=True, header_style="bold magenta")
    tabla.add_column("Palabra", style="cyan", justify="left")
    tabla.add_column("Frecuencia", style="green", justify="right")
    # ... se a√±aden las filas ...
    console.print(tabla)
    ```

---

## 9. Sistema de Men√∫ Interactivo

El script ya no se cierra tras mostrar los gr√°ficos, ni te obliga a ver todas las im√°genes a la vez. Hemos implementado un **bucle interactivo**:

1.  **Selector de Figuras**: Al ejecutar el script, la terminal te preguntar√° qu√© deseas visualizar (Opci√≥n 1 para el Dashboard 360¬∞, Opci√≥n 2 para la Comparativa).
2.  **Regeneraci√≥n "Fresh"**: Debido a que Matplotlib libera memoria al cerrar una ventana, el script regenera la imagen completa cada vez que la seleccionas en el men√∫. Esto evita el problema de las "ventanas en blanco".
3.  **Salida Controlada**: La opci√≥n `3` permite cerrar el programa de forma limpia con un mensaje de despedida.

---

### Conclusi√≥n Detallada del Ejercicio

La limpieza de texto es un paso **obligatorio** en el Procesamiento de Lenguaje Natural (NLP) por las siguientes razones fundamentales:

*   **Reducci√≥n de Dimensionalidad**: Al eliminar palabras vac√≠as (stopwords), reducimos el volumen de datos innecesarios, permitiendo que los algoritmos de IA se centren solo en los t√©rminos que realmente transmiten informaci√≥n valiosa.
*   **Claridad Sem√°ntica**: Sin limpieza, los t√©rminos m√°s comunes del idioma opacan a las palabras clave. Filtrar el ruido es como "limpiar una lente" para ver con nitidez el tema real del texto.
*   **Ahorro de C√≥mputo**: Procesar miles de veces palabras como "el" o "de" consume recursos de CPU y memoria sin aportar valor. La eficiencia es clave en modelos de lenguaje a gran escala.
*   **An√°lisis de Sentimiento**: Al aislar adjetivos y verbos clave (como "fant√°stico" o "terrible"), podemos asignar una puntuaci√≥n emocional al texto, transformando simples palabras en datos estrat√©gicos para la toma de decisiones.
